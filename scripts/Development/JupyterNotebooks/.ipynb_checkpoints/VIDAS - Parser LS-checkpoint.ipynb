{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "basePath='//mxns.loc//shares//NA-Instruments//VIDAS//VIDAS_LIMS//'\n",
    "colsOrder=['Sample.Sample_Number', 'Test.Analysis','Result.Name', 'Result.Entry', 'Result.Entered_By','Result.Instrument']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate the result name\n",
    "def generateResultname(testIdentifier,variable):\n",
    "    if(variable=='R2'):\n",
    "        return str(testIdentifier)\n",
    "    else:\n",
    "        return str('OD'+str(testIdentifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion to Create a folder if it dosen't exsist.\n",
    "def createFolderIfNotExsist(folderPath):\n",
    "    if os.path.exists(folderPath):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moce to ARK folder\n",
    "def moveFiletoArkFolder(arkPath,sourcePath,fname):\n",
    "    arkDest = arkPath + fname[:-4] + '.bak' #Backup the processed file\n",
    "    os.rename(sourcePath, arkDest)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the file\n",
    "def writeFile(dframe,lab,instName,arkPath,basePath,sourcePath):\n",
    "    timestr = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "    importerFilePath = basePath + lab+'_IMPORTER//'+instName+'_' + timestr + '.csv'\n",
    "    dframe.to_csv(importerFilePath, index=False, encoding=\"utf-8\",quotechar='\"',quoting=csv.QUOTE_NONNUMERIC) # write  out the file to be imported\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\configFiles\\VIDASParserConfig.json', 'r') as f:\n",
    "    config = json.loads(f)\n",
    "    for d1 in config:\n",
    "        lab=d1\n",
    "        labcount=int(config[d1]['count'])\n",
    "        labImporterPath=config[d1]['importerPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "createFolderIfNotExsist(labImporterPath)\n",
    "li = []\n",
    "print('Processing Files for :'+lab)\n",
    "for each in range(1,labcount+1):\n",
    "    instName=lab+'VIDAS'+str(each)\n",
    "    sourceFolderPath=basePath+instName+'//'\n",
    "    arkFolderPath=sourceFolderPath+'Archive//'+datetime.now().strftime('%Y')+'//'+datetime.now().strftime('%m_%d')+'//'\n",
    "    #checking the exsitnace of importer path\n",
    "    createFolderIfNotExsist(sourceFolderPath)\n",
    "    #checking the exsitnace of Archive directory and path\n",
    "    createFolderIfNotExsist(arkFolderPath)\n",
    "    files = os.listdir(sourceFolderPath)\n",
    "    for filename in files:\n",
    "        if fnmatch.fnmatch(filename,'*.CSV'):\n",
    "            filePath = sourceFolderPath + str(filename)\n",
    "            try:\n",
    "                rawdf = pd.read_csv(filePath,index_col=None,header=None)\n",
    "                rawdf['instrumentName']=instName\n",
    "                li.append(rawdf)\n",
    "                print('Processed :'+filename)\n",
    "                moveFiletoArkFolder(arkFolderPath,sourceFolderPath,filename)\n",
    "            except:\n",
    "                continue\n",
    "raw_data = pd.concat(li, axis=0, ignore_index=True)\n",
    "raw_data['specimenIdentifier'] =raw_data[0]\n",
    "raw_data['testIdentifier'] =raw_data[1]\n",
    "raw_data['R1'] =raw_data[5]\n",
    "raw_data['R2'] =raw_data[2]\n",
    "raw_data['patientIdentifier'] = raw_data[4]\n",
    "raw_data = raw_data[np.isfinite(raw_data[\"patientIdentifier\"])]\n",
    "raw_data['patientIdentifier']=raw_data['patientIdentifier'].astype(int)\n",
    "raw_data[\"samplenumber\"] = raw_data[\"patientIdentifier\"].map(str) + raw_data[\"specimenIdentifier\"].str[-6:]\n",
    "dfResult = pd.melt(raw_data, \n",
    "                   id_vars=['instrumentName','specimenIdentifier','testIdentifier','samplenumber'], value_vars=['R1', 'R2'])\n",
    "dfResult['Result.Name'] = dfResult.apply(lambda x: generateResultname(x.testIdentifier,x.variable),axis=1)\n",
    "dfResult = dfResult.sort_values(by=['samplenumber'])\n",
    "dfResult['Test.Analysis'] = 'VIDAS'\n",
    "dfResult['Result.Entered_By'] = lab+'_VIDAS_IMPORTER'\n",
    "dfResult = dfResult.rename(index=str,\n",
    "columns={'samplenumber': 'Sample.Sample_Number', 'value': 'Result.Entry','instrumentName':'Result.Instrument'})\n",
    "dfResult=dfResult[colsOrder]\n",
    "#Writes the File to the  ARK, Importer Folders\n",
    "writeFile(dfResult,lab,instName,arkFolderPath,basePath,sourceFolderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEachLabFiles(lab,labcount,labImporterPath,basePath):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
